{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need pandas for data manipulation, sklearn for machine learning algorithms and metrics.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "\n",
    "# Suppress runtime warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to load the CSV file into a DataFrame.\n",
    "df = pd.read_csv('crime_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We convert dates to datetime format and then to Unix timestamp (a numerical format).\n",
    "# We also convert categorical variables to numeric ones using LabelEncoder.\n",
    "# We drop rows with missing values as they can cause issues with many machine learning algorithms.\n",
    "df['Date Rptd'] = pd.to_datetime(df['Date Rptd'])\n",
    "df['DATE OCC'] = pd.to_datetime(df['DATE OCC'])\n",
    "df['Date Rptd'] = df['Date Rptd'].apply(lambda x: x.timestamp())\n",
    "df['DATE OCC'] = df['DATE OCC'].apply(lambda x: x.timestamp())\n",
    "le = LabelEncoder()\n",
    "df['Crm Cd Desc'] = le.fit_transform(df['Crm Cd Desc'].astype(str))\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object' and col != 'Crm Cd Desc':\n",
    "        df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "df = df.dropna()\n",
    "\n",
    "# We split the data into features (X) and target (y), and then into training set and test set.\n",
    "X = df.drop('Crm Cd Desc', axis=1)\n",
    "y = df['Crm Cd Desc']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We initialize the RandomForestClassifier and train it on the training set.\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         precision    recall  f1-score   support\n",
      "\n",
      "         ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT       1.00      0.00      0.00         1\n",
      "                               BATTERY - SIMPLE ASSAULT       1.00      1.00      1.00         1\n",
      "                                        BRANDISH WEAPON       1.00      1.00      1.00         4\n",
      "                  INTIMATE PARTNER - AGGRAVATED ASSAULT       1.00      1.00      1.00         1\n",
      "                                             KIDNAPPING       1.00      0.00      0.00         1\n",
      "                                        ORAL COPULATION       1.00      0.00      0.00         2\n",
      "                                                ROBBERY       0.50      1.00      0.67         1\n",
      "                    SEXUAL PENETRATION W/FOREIGN OBJECT       0.00      1.00      0.00         0\n",
      "SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO ANUS OTH       1.00      0.00      0.00         1\n",
      "\n",
      "                                               accuracy                           0.58        12\n",
      "                                              macro avg       0.83      0.56      0.41        12\n",
      "                                           weighted avg       0.96      0.58      0.56        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We make predictions on the test set and print a classification report to evaluate the model's performance.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a dictionary that maps labels to descriptions\n",
    "label_to_desc = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "# Replace labels with descriptions in y_test and y_pred\n",
    "y_test_desc = [label_to_desc[label] for label in y_test]\n",
    "y_pred_desc = [label_to_desc[label] for label in y_pred]\n",
    "\n",
    "# Print a classification report with actual descriptions\n",
    "print(classification_report(y_test_desc, y_pred_desc, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s what each term means:\n",
    "\n",
    "- Precision: This is the ability of the classifier not to label a positive sample as negative. It’s calculated as the number of true positives (TP) over the number of true positives plus the number of false positives (FP).\n",
    "\n",
    "- Recall: This is the ability of the classifier to find all the positive samples. It can be calculated as the number of true positives (TP) over the number of true positives plus the number of false negatives (FN).\n",
    "\n",
    "- F1-Score: This is the weighted harmonic mean of precision and recall. The best possible F1-score would be 1.0 and the worst would be 0.0. F1-score is a good way to summarize the evaluation of the model into a single number.\n",
    "\n",
    "- Support: This is the number of samples of the true response that lie in that class.\n",
    "\n",
    "The ‘macro avg’ row calculates the metric for each class and then takes the average (hence treating all classes equally), whereas the ‘weighted avg’ row calculates the metric for each class and takes the average weighted by the number of true instances for each class.\n",
    "\n",
    "The ‘accuracy’ row is the ratio of correct predictions to total predictions.\n",
    "\n",
    "In your case, the model has an accuracy of 0.58, which means it made correct predictions for 58% of the input samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report you have here provides a detailed breakdown of your model's performance for each class in your dataset. Here's what we can interpret from the results:\n",
    "\n",
    "- **Precision**: This is the ratio of true positives to the sum of true positives and false positives. A high precision indicates a low false positive rate. For example, the model has a precision of 1.00 for 'BATTERY - SIMPLE ASSAULT', which means it correctly identified all instances of this class and did not mistakenly classify any other instances as this class.\n",
    "\n",
    "- **Recall**: This is the ratio of true positives to the sum of true positives and false negatives. A high recall indicates a low false negative rate. For example, the model has a recall of 1.00 for 'BRANDISH WEAPON', which means it correctly identified all instances of this class and did not miss any.\n",
    "\n",
    "- **F1-score**: This is the harmonic mean of precision and recall, and it tries to balance the two. An F1 score of 1 is perfect, and 0 means that either the precision or the recall is zero. For example, the model has an F1 score of 1.00 for 'INTIMATE PARTNER - AGGRAVATED ASSAULT', indicating a good balance of precision and recall for this class.\n",
    "\n",
    "- **Support**: This is the number of actual occurrences of the class in the test data set. For example, there is only 1 instance of 'ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT' in your test data.\n",
    "\n",
    "- **Accuracy**: This is the ratio of correct predictions to total predictions. The overall accuracy of your model is 0.58, which means it made correct predictions for 58% of the instances in the test data.\n",
    "\n",
    "- **Macro Avg**: This is the average of the unweighted mean per label. \n",
    "\n",
    "- **Weighted Avg**: This is the average of the support-weighted mean per label.\n",
    "\n",
    "From the results, it seems like the model is performing well for some classes ('BATTERY - SIMPLE ASSAULT', 'BRANDISH WEAPON', 'INTIMATE PARTNER - AGGRAVATED ASSAULT'), but not for others ('ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT', 'KIDNAPPING', 'ORAL COPULATION'). This could be due to a variety of factors, such as class imbalance in your training data, or it could be that your model needs further tuning or a different approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
